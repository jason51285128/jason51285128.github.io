---
layout: post
title: spark教程 
categories: 大数据 
tags: spark 
---

# spark

## 基本概念

*  RDD：是弹性分布式数据集（Resilient Distributed Dataset）的简称，是分布式内存的一个抽象概念，提供了一种高度受限的共享内存模型；
*  DAG：是Directed Acyclic Graph（有向无环图）的简称，反映RDD之间的依赖关系；
*  Executor：是运行在工作节点（Worker Node）上的一个进程，负责运行任务，并为应用程序存储数据；
*  应用：用户编写的Spark应用程序；
*  任务：运行在Executor上的工作单元；
*  作业：一个作业包含多个RDD及作用于相应RDD上的各种操作；
*  阶段：是作业的基本调度单位，一个作业会分为多组任务，每组任务被称为“阶段”，或者也被称为“任务集”

## spark架构

![Spark运行架构.jpg]({{site.baseurl}}/assets/images/Spark运行架构.jpg)
![spark应用架构.jpg]({{site.baseurl}}/assets/images/spark应用架构.jpg)
![Spark运行流程图.jpg]({{site.baseurl}}/assets/images/Spark运行流程图.jpg)

[参考](http://dblab.xmu.edu.cn/blog/1711-2/)


## RDD的设计与运行原理

一个RDD就是一个分布式对象集合，本质上是一个只读的分区记录集合，每个RDD可以分成多个分区，每个分区就是一个数据集片段，并且一个RDD的不同分区可以被保存到集群中不同的节点上，从而可以在集群中的不同节点上进行并行计算。

![RDD的转换和行动操作.jpg]({{site.baseurl}}/assets/images/RDD的转换和行动操作.jpg)
![RDD执行过程的一个实例.jpg]({{site.baseurl}}/assets/images/RDD执行过程的一个实例.jpg)
![RDD在Spark中的运行过程.jpg]({{site.baseurl}}/assets/images/RDD在Spark中的运行过程.jpg)

[参考](http://dblab.xmu.edu.cn/blog/1681-2/)

## spark的部署模式

[参考](http://dblab.xmu.edu.cn/blog/1713-2/)


## rdd 编程

[参考](http://dblab.xmu.edu.cn/blog/1700-2/)


## 共享变量

[参考](http://dblab.xmu.edu.cn/blog/1707-2/)

## spark sql

[参考](http://dblab.xmu.edu.cn/blog/1718-2/)

RDD是分布式的 Java对象的集合，比如，RDD[Person]是以Person为类型参数，但是，Person类的内部结构对于RDD而言却是不可知的。DataFrame是一种以RDD为基础的分布式数据集，也就是分布式的Row对象的集合（每个Row对象代表一行记录），提供了详细的结构信息，也就是我们经常说的模式（schema），Spark SQL可以清楚地知道该数据集中包含哪些列、每列的名称和类型。RDD是分布式的对象集合，data

## 参考连接

[教程](http://dblab.xmu.edu.cn/blog/1709-2/)



